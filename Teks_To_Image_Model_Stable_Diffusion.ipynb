{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/club20s/t2i/blob/main/Teks_To_Image_Model_Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEKS KE GAMBAR DENGAN STABLE DIFFUSION"
      ],
      "metadata": {
        "id": "WRkImjggNUij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LIBRARY YANG HARUS DI INSTALL DI PYTHON TERLEBIH DAHULU\n",
        "\n",
        "!pip install diffusers transformers ipywidgets matplotlib torch tqdm accelerate\n",
        "!pip install tensorflow\n",
        "!pip install torch torchvision\n",
        "!pip install seaborn\n",
        "!pip install opencv-python\n",
        "!pip install --upgrade gradio\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install deep-translator\n",
        "!pip install httpx==0.23.0\n"
      ],
      "metadata": {
        "id": "lMrfQTSNNdep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import CLIPTokenizer, CLIPTextModel\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import time\n",
        "\n",
        "\n",
        "# Set up device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize pipeline, tokenizer, and text encoder\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16).to(device)\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "# Create a folder for saving images and results\n",
        "output_folder = \"generated_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Function to define the default beta schedule\n",
        "def default_beta_schedule(num_steps, beta_start=0.1, beta_end=0.2):\n",
        "    return torch.linspace(beta_start, beta_end, num_steps, dtype=torch.float32).to(device)\n",
        "\n",
        "# Function to calculate noise on image tensor\n",
        "def calculate_noise(image_tensor):\n",
        "    return torch.mean(torch.abs(image_tensor - image_tensor.mean())).item()\n",
        "\n",
        "# Function to calculate noise percentage\n",
        "def calculate_noise_percentage(noise_level, max_pixel_value=1.0):\n",
        "    return (noise_level / max_pixel_value) * 100\n",
        "\n",
        "# Forward diffusion function\n",
        "def forward_diffusion(latents, beta, noise):\n",
        "    beta_tensor = beta.clone().detach().to(latents.device)\n",
        "    return torch.sqrt(1 - beta_tensor) * latents + torch.sqrt(beta_tensor) * noise\n",
        "\n",
        "# Reverse diffusion function\n",
        "def reverse_diffusion(latents, beta, noise):\n",
        "    beta_tensor = beta.clone().detach().to(latents.device)\n",
        "    return (latents - torch.sqrt(beta_tensor) * noise) / torch.sqrt(1 - beta_tensor)\n",
        "\n",
        "# Function to save and display generated image\n",
        "def display_image(image, title=\"Generated Image\", save_path=None):\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "# Function to calculate PSNR\n",
        "def calculate_psnr(img1, img2):\n",
        "    img1 = img1.to(device) if isinstance(img1, torch.Tensor) else transforms.ToTensor()(img1).to(device)\n",
        "    img2 = img2.to(device)\n",
        "    mse = torch.mean((img1 - img2) ** 2)\n",
        "    return float('inf') if mse == 0 else 20 * torch.log10(1.0 / torch.sqrt(mse + 1e-8))\n",
        "\n",
        "# Function to calculate SSIM\n",
        "def calculate_ssim(img1, img2, win_size=3):\n",
        "    img1 = img1.to(device) if isinstance(img1, torch.Tensor) else transforms.ToTensor()(img1).to(device)\n",
        "    img2 = img2.to(device)\n",
        "    img1_np = img1.squeeze(0).cpu().numpy()\n",
        "    img2_np = img2.squeeze(0).cpu().numpy()\n",
        "    if img1_np.shape[1] < win_size or img1_np.shape[2] < win_size:\n",
        "        raise ValueError(f\"Image too small to compute SSIM; minimum size {win_size}x{win_size} required.\")\n",
        "    return ssim(img1_np, img2_np, multichannel=True, win_size=win_size, data_range=1.0)\n",
        "\n",
        "# Function to evaluate image\n",
        "def evaluate_image(reverse_noised_image, generated_tensor):\n",
        "    psnr_value = calculate_psnr(reverse_noised_image, generated_tensor)\n",
        "    try:\n",
        "        ssim_value = calculate_ssim(reverse_noised_image, generated_tensor)\n",
        "    except ValueError as e:\n",
        "        ssim_value = str(e)\n",
        "    return psnr_value, ssim_value\n",
        "\n",
        "\n",
        "# Function to track PSNR and SSIM across diffusion steps\n",
        "def track_metrics(generated_tensor, betas, num_steps=100):\n",
        "    psnr_values = []\n",
        "    ssim_values = []\n",
        "    noise = torch.randn_like(generated_tensor).to(device)\n",
        "    noisy_image = generated_tensor.clone()\n",
        "\n",
        "    # Forward diffusion\n",
        "    for i in range(num_steps):\n",
        "        beta = betas[i] # Ambil beta untuk langkah i\n",
        "        noisy_image = forward_diffusion(noisy_image, beta, noise) # Proses difusi maju\n",
        "        psnr_value = calculate_psnr(generated_tensor, noisy_image)\n",
        "        try:\n",
        "            ssim_value = calculate_ssim(generated_tensor, noisy_image)\n",
        "        except ValueError:\n",
        "            ssim_value = None\n",
        "        psnr_values.append(float(psnr_value))\n",
        "        ssim_values.append(float(ssim_value) if ssim_value is not None else np.nan)\n",
        "\n",
        "    # Reverse diffusion\n",
        "    for i in range(num_steps - 1, -1, -1):\n",
        "        beta = betas[i]\n",
        "        noisy_image = reverse_diffusion(noisy_image, beta, noise)\n",
        "        psnr_value = calculate_psnr(generated_tensor, noisy_image)\n",
        "        try:\n",
        "            ssim_value = calculate_ssim(generated_tensor, noisy_image)\n",
        "        except ValueError:\n",
        "            ssim_value = None\n",
        "        psnr_values.append(float(psnr_value))\n",
        "        ssim_values.append(float(ssim_value) if ssim_value is not None else np.nan)\n",
        "\n",
        "    return psnr_values, ssim_values\n",
        "\n",
        "\n",
        "\n",
        "# Function to process image generation with Self-Attention and Cross-Attention\n",
        "def process_image(prompt, selected_theme, selected_style):\n",
        "    combined_prompt = f\"{prompt} {selected_theme} {selected_style}\"\n",
        "    # Tokenize and encode the prompt\n",
        "    text_input = tokenizer(combined_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    print(\"Prompt yang telah di-tokenisasi:\", text_input)\n",
        "    # Decode the tokenized prompt\n",
        "    decoded_text = tokenizer.decode(text_input.squeeze(0))\n",
        "    print(\"Prompt yang telah didekode:\", decoded_text)\n",
        "    embeddings = text_encoder(text_input).last_hidden_state\n",
        "    generated_image = pipeline(prompt=combined_prompt, guidance_scale=7.5, num_inference_steps=50)[\"images\"][0]\n",
        "    return transforms.ToTensor()(generated_image).unsqueeze(0).to(device)\n",
        "\n",
        "# Create widgets for prompt, theme, and style input\n",
        "prompt_widget = widgets.Text(placeholder='Masukkan prompt untuk pembuatan gambar', description='Prompt:')\n",
        "theme_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        '', 'Flying', 'Underwater', 'Space', 'Fantasy', 'Cyberpunk', 'Steampunk',\n",
        "        'Forest', 'Desert', 'Cityscape', 'Mountain', 'Ocean', 'Abstract',\n",
        "        'Sci-fi', 'Medieval', 'Winter', 'Summer', 'Spring', 'Autumn',\n",
        "        'Future', 'Wild West', 'Jungle', 'Deep Sea', 'Outer Space',\n",
        "        'Robot World', 'Alien Planet', 'Dreamscape', 'Apocalypse',\n",
        "        'Neon City', 'Magic Realm', 'Steampunk City', 'Mythical Creatures',\n",
        "        'Post-Apocalyptic', 'Enchanted Forest', 'Galactic Empire', 'Vintage',\n",
        "        'Art Deco', 'Fairytale', 'Futuristic City', 'Retro', 'Alien Landscape',\n",
        "        'Cybernetic World', 'Celestial', 'Whimsical', 'Dark Fantasy'\n",
        "    ],\n",
        "    description='Tema:',\n",
        ")\n",
        "style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        '', 'Van Gogh', 'Edvard Munch', 'Pablo Picasso', 'Johannes Vermeer',\n",
        "        'Studio Ghibli', 'Leonardo Da Vinci', 'Claude Monet', 'Henri Matisse',\n",
        "        'Jackson Pollock', 'Salvador Dalí', 'Frida Kahlo', 'Gustav Klimt',\n",
        "        'Andy Warhol', 'Piet Mondrian', 'Wassily Kandinsky', 'Paul Cézanne',\n",
        "        'Yayoi Kusama', 'Keith Haring', 'Damien Hirst', 'Renaissance',\n",
        "        'Surrealism', 'Impressionism', 'Cubism', 'Modern Art', 'Pop Art',\n",
        "        'Minimalism', 'Anime', 'Realism', 'Futurism', 'Baroque',\n",
        "        'Expressionism', 'Gothic', 'Photorealism', 'Graffiti', 'Pixel Art',\n",
        "        'Fantasy Art', 'Comic Book Style', 'Retro Futurism', 'Noir',\n",
        "        'Abstract Art', 'Flat Art', '3D Art', 'High Contrast', 'Concept Art',\n",
        "        'Art Deco'\n",
        "    ],\n",
        "    description='Gaya:',\n",
        ")\n",
        "\n",
        "# Button to trigger image generation\n",
        "generate_button = widgets.Button(description=\"Buat Gambar\")\n",
        "\n",
        "def on_generate_clicked(b):\n",
        "    prompt = prompt_widget.value\n",
        "    selected_theme = theme_widget.value\n",
        "    selected_style = style_widget.value\n",
        "    # Start timing\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 1: Process image generation\n",
        "    generated_tensor = process_image(prompt, selected_theme, selected_style)\n",
        "\n",
        "    # Save and display the initial generated image\n",
        "    initial_image_path = os.path.join(output_folder, \"initial_generated_image.png\")\n",
        "    display_image(transforms.ToPILImage()(generated_tensor.squeeze(0).cpu()), title=\"Gambar Awal yang Dihasilkan\", save_path=initial_image_path)\n",
        "\n",
        "    # Step 2: Forward diffusion (adding noise)\n",
        "    num_steps = 50  # Set the number of diffusion steps\n",
        "    betas = default_beta_schedule(num_steps)\n",
        "    beta = betas[0]  # Use the first beta value for this example\n",
        "\n",
        "\n",
        "    psnr_values, ssim_values = track_metrics(generated_tensor, betas, num_steps)\n",
        "    print(f\"PSNR Values: {psnr_values}\")\n",
        "    print(f\"SSIM Values: {ssim_values}\")\n",
        "\n",
        "    noise = torch.randn_like(generated_tensor).to(device)\n",
        "    forward_noised_image = forward_diffusion(generated_tensor, beta, noise)\n",
        "\n",
        "    # Convert and display the image with noise from forward diffusion\n",
        "    forward_noised_image_pil = transforms.ToPILImage()(forward_noised_image.squeeze(0).cpu())\n",
        "    forward_noised_image_path = os.path.join(output_folder, \"forward_noised_image.png\")\n",
        "    forward_noise_level = calculate_noise(forward_noised_image)\n",
        "    forward_noise_percentage = calculate_noise_percentage(forward_noise_level)\n",
        "\n",
        "    print(f\"Forward diffusion: Tingkat Noise: {forward_noise_level}, Persentase Noise: {forward_noise_percentage:.2f}%\")\n",
        "    display_image(forward_noised_image_pil, title=\"Gambar dengan Noise Forward\", save_path=forward_noised_image_path)\n",
        "\n",
        "    # Step 3: Reverse diffusion (removing noise)\n",
        "    reverse_noised_image = reverse_diffusion(forward_noised_image, beta, noise)\n",
        "    reverse_noised_image_pil = transforms.ToPILImage()(reverse_noised_image.squeeze(0).cpu())\n",
        "    reverse_noised_image_path = os.path.join(output_folder, \"reverse_noised_image.png\")\n",
        "    print(f\"Reverse diffusion: Tingkat Noise: {calculate_noise(reverse_noised_image)}, Persentase Noise: {calculate_noise_percentage(calculate_noise(reverse_noised_image)):.2f}%\")\n",
        "\n",
        "    print(\"Evaluating image quality...\")\n",
        "    psnr_value, ssim_value = evaluate_image(reverse_noised_image_pil, generated_tensor)\n",
        "    print(f\"PSNR: {psnr_value} dB, SSIM: {ssim_value}\")\n",
        "\n",
        "\n",
        "    # Save and display the reverse diffusion image\n",
        "    display_image(reverse_noised_image_pil, title=\"Gambar dengan Noise Reverse\", save_path=reverse_noised_image_path)\n",
        "\n",
        "    # Plot PSNR and SSIM values\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot PSNR values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(len(psnr_values)), psnr_values, label='PSNR')\n",
        "    plt.xlabel('Diffusion Step')\n",
        "    plt.ylabel('PSNR')\n",
        "    plt.title('PSNR across Diffusion Steps')\n",
        "\n",
        "    # Plot SSIM values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(len(ssim_values)), ssim_values, label='SSIM', color='orange')\n",
        "    plt.xlabel('Diffusion Step')\n",
        "    plt.ylabel('SSIM')\n",
        "    plt.title('SSIM across Diffusion Steps')\n",
        "\n",
        "\n",
        "    # End timing\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Waktu mulai: {start_time:.2f} detik\")\n",
        "    print(f\"Waktu selesai: {end_time:.2f} detik\")\n",
        "    print(f\"Durasi total: {duration:.2f} detik\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "generate_button.on_click(on_generate_clicked)\n",
        "display(prompt_widget, theme_widget, style_widget, generate_button)\n",
        "\n",
        "\n",
        "#satuan dB (decibel) digunakan untuk mengukur rasio antara nilai maksimum sinyal asli (atau puncak sinyal) dengan tingkat derau (noise) pada sinyal tersebut\n"
      ],
      "metadata": {
        "id": "fE8inxURNYSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}